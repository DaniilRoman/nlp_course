{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uHUidi_S6JC3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "mQYi0n328wHI",
    "outputId": "5d0e7e3e-66eb-462e-e6b2-c48dd548d7a1"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    data_prefix = '/content/drive/My Drive/NLP'\n",
    "except ModuleNotFoundError:\n",
    "    data_prefix = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "on4Ta9G67Dm2"
   },
   "outputs": [],
   "source": [
    "raw_train = pd.read_parquet(os.path.join(data_prefix, 'train.parquet'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разделение данных на тренировочную и валидационную выборки \n",
    "\n",
    "В курсе по NLP от ШАДа рекомендуют делать это разделение до начала предварительной обработки, чтобы нигде не накосячить, поэтому мы тоже так сделаем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_target = raw_train['target']\n",
    "raw_data   = raw_train.drop(['target'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_target, test_target = train_test_split(raw_data, raw_target,\n",
    "                                                                    test_size=0.25, random_state=47)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предварительная обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/droman/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from data_preprocessing import remove_html_tags, stay_only_a_z, tokenize_by_word, remove_stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Препроцессинг для Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def body_preprocess(text):\n",
    "#     text = remove_html_tags(text)\n",
    "    text = stay_only_a_z(text)\n",
    "    text = tokenize_by_word(text)\n",
    "#     text = remove_stop_words(text)\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выполним препроцессинг для данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-a2c9aaefb20d>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['Body'] = train_data['Body'].apply(body_preprocess)\n",
      "<ipython-input-31-a2c9aaefb20d>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data ['Body'] = test_data ['Body'].apply(body_preprocess)\n"
     ]
    }
   ],
   "source": [
    "train_data['Body'] = train_data['Body'].apply(body_preprocess)\n",
    "test_data ['Body'] = test_data ['Body'].apply(body_preprocess)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Препроцессинг для Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_preprocessing(text):\n",
    "    text = stay_only_a_z(text)\n",
    "    text = tokenize_by_word(text)\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-e5c6a9bb7a00>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data['Title'] = train_data['Title'].apply(title_preprocessing)\n",
      "<ipython-input-33-e5c6a9bb7a00>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data ['Title'] = test_data ['Title'].apply(title_preprocessing)\n"
     ]
    }
   ],
   "source": [
    "train_data['Title'] = train_data['Title'].apply(title_preprocessing)\n",
    "test_data ['Title'] = test_data ['Title'].apply(title_preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Секция для определения исходных фичей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_features(__data):\n",
    "    __data['text'] = __data['Title'] + ' ' + __data['Body']\n",
    "    return __data.drop(['Tags', 'Title', 'Body'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "YlmAgFAA-jNC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-e70b16de7c75>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  __data['text'] = __data['Title'] + ' ' + __data['Body']\n"
     ]
    }
   ],
   "source": [
    "train_data = get_raw_features(train_data)\n",
    "test_data = get_raw_features(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Не забыть уйти от Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data['text']\n",
    "test_data = test_data['text']\n",
    "\n",
    "train_target = train_target.values\n",
    "test_target  = test_target.values"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-sfomX7KCdU-",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# words = train_target[0].split()\n",
    "\n",
    "def get_sentences(series_data):\n",
    "    list_of_lists_data = [i.split() for i in series_data]\n",
    "    return list_of_lists_data"
   ],
   "execution_count": 73,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w2v_str_representation_mean(text, model):\n",
    "    words = text.split()\n",
    "    words_representation = [model[word] for word in words if word in model.wv.vocab]\n",
    "    return np.mean(words_representation, axis=0)\n",
    "\n",
    "def get_w2v_str_representation_sum(text, model):\n",
    "    words = text.split()\n",
    "    words_representation = [model[word] for word in words if word in model.wv.vocab]\n",
    "    return np.sum(words_representation, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_vectorizer_sum(train, test, model):\n",
    "    return ([get_w2v_str_representation_sum(text, model) for text in train],\n",
    "            [get_w2v_str_representation_sum(text, model) for text in test])\n",
    "\n",
    "def w2v_vectorizer_mean(train, test, model):\n",
    "    return ([get_w2v_str_representation_mean(text, model) for text in train],\n",
    "            [get_w2v_str_representation_mean(text, model) for text in test])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "OWN W2V"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-74-d5ca81e51b98>:7: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  model.train(sentences, total_examples=model.corpus_count, epochs=model.iter)  # train word vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": "(21341324, 25694735)"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "# sentences = [[\"cat\", \"say\", \"meow\"], [\"dog\", \"say\", \"woof\"]]\n",
    "sentences = get_sentences(train_data.append(test_data))\n",
    "\n",
    "try:\n",
    "    model = Word2Vec.load(\"own_w2v\")\n",
    "except Exception:\n",
    "    model = Word2Vec(min_count=1)\n",
    "    model.build_vocab(sentences)  # prepare the model vocabulary\n",
    "    model.train(sentences, total_examples=model.corpus_count, epochs=model.iter)  # train word vectors\n",
    "\n",
    "    model.save(\"own_w2v\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gp8HDPeKJadX"
   },
   "source": [
    "# Построение классификаторов\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTCHZxyhKhIj"
   },
   "source": [
    "## 3. Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "phyDRDQbKgpe"
   },
   "outputs": [],
   "source": [
    "def lr_score(trainX, trainY, testX, testY):\n",
    "    lr_classifier = LogisticRegression()\n",
    "    lr_classifier.fit(trainX, trainY)\n",
    "    return lr_classifier.score(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "803CUXuNlpoR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'========================================================================================================================\\n========================================================================================================================\\n========================================================================================================================\\n'"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''========================================================================================================================\n",
    "========================================================================================================================\n",
    "========================================================================================================================\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "id": "XTUyvezPlu3r",
    "outputId": "b2ae5aae-0dc9-4358-cbf8-6a505610feab"
   },
   "outputs": [],
   "source": [
    "def visualize_results(score):\n",
    "    print(score)\n",
    "\n",
    "def base_pipeline(train_x, train_y, test_x, test_y,\n",
    "                  vectorizer, scorer):\n",
    "    vectorized_train_x, vectorized_test_x = vectorizer(train_x, test_x, model)\n",
    "    score = scorer(vectorized_train_x, train_y, vectorized_test_x, test_y)\n",
    "    visualize_results(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-59-d47030294076>:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  words_representation = [model[word] for word in words if word in model.wv.vocab]\n",
      "/home/droman/Documents/diploma/venv/lib/python3.8/site-packages/sklearn/linear_model/logistic.py:430: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  warnings.warn(\"Default solver will be changed to 'lbfgs' in 0.22. \"\n",
      "/home/droman/Documents/diploma/venv/lib/python3.8/site-packages/sklearn/linear_model/logistic.py:467: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  warnings.warn(\"Default multi_class will be changed to 'auto' in\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8088333333333333\n"
     ]
    }
   ],
   "source": [
    "base_pipeline(train_data, train_target, test_data, test_target,\n",
    "              w2v_vectorizer_mean, lr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}