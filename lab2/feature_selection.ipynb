{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../train_dist.csv', index_col=\"pair_id\")\n",
    "test = pd.read_csv('../test_dist.csv', index_col=\"pair_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name_1</th>\n",
       "      <th>name_2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>lemm_name_1</th>\n",
       "      <th>lemm_name_2</th>\n",
       "      <th>stopw_name_1</th>\n",
       "      <th>stopw_name_2</th>\n",
       "      <th>clean_name_1</th>\n",
       "      <th>clean_name_2</th>\n",
       "      <th>...</th>\n",
       "      <th>lemm_strcmp95</th>\n",
       "      <th>lemm_needleman_wunsch</th>\n",
       "      <th>lemm_sorensen</th>\n",
       "      <th>lemm_tversky</th>\n",
       "      <th>lemm_overlap</th>\n",
       "      <th>lemm_monge_elkan</th>\n",
       "      <th>lemm_bag</th>\n",
       "      <th>lemm_lcsseq</th>\n",
       "      <th>lemm_lcsstr</th>\n",
       "      <th>lemm_ratcliff_obershelp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pair_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>iko industries</td>\n",
       "      <td>enormous industrial trade</td>\n",
       "      <td>0</td>\n",
       "      <td>iko industry</td>\n",
       "      <td>enormous industrial trade</td>\n",
       "      <td>iko industry</td>\n",
       "      <td>enormous industrial trade</td>\n",
       "      <td>iko</td>\n",
       "      <td>enormous</td>\n",
       "      <td>...</td>\n",
       "      <td>0.579852</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>15</td>\n",
       "      <td>o industr</td>\n",
       "      <td>industr</td>\n",
       "      <td>0.486486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>apcotex industries</td>\n",
       "      <td>technocraft industries</td>\n",
       "      <td>0</td>\n",
       "      <td>apcotex industry</td>\n",
       "      <td>technocraft industry</td>\n",
       "      <td>apcotex industry</td>\n",
       "      <td>technocraft industry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>technocraft</td>\n",
       "      <td>...</td>\n",
       "      <td>0.726726</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>6</td>\n",
       "      <td>cot industry</td>\n",
       "      <td>industry</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>rishichem distributors</td>\n",
       "      <td>dsa</td>\n",
       "      <td>0</td>\n",
       "      <td>rishichem distributor</td>\n",
       "      <td>dsa</td>\n",
       "      <td>rishichem distributor</td>\n",
       "      <td>dsa</td>\n",
       "      <td>rishichem distributor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.498413</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.006803</td>\n",
       "      <td>19</td>\n",
       "      <td>ds</td>\n",
       "      <td>s</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>powermax rubber factory</td>\n",
       "      <td>co one</td>\n",
       "      <td>0</td>\n",
       "      <td>powermax rubber factory</td>\n",
       "      <td>co one</td>\n",
       "      <td>powermax rubber factory</td>\n",
       "      <td>co one</td>\n",
       "      <td>powermax factory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.474396</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.013233</td>\n",
       "      <td>18</td>\n",
       "      <td>o e</td>\n",
       "      <td>o</td>\n",
       "      <td>0.137931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>tress as</td>\n",
       "      <td>longyou industries park zhejiang</td>\n",
       "      <td>0</td>\n",
       "      <td>tress a</td>\n",
       "      <td>longyou industry park zhejiang</td>\n",
       "      <td>tress</td>\n",
       "      <td>longyou industry park zhejiang</td>\n",
       "      <td>tress</td>\n",
       "      <td>longyou park</td>\n",
       "      <td>...</td>\n",
       "      <td>0.528889</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>24</td>\n",
       "      <td>tr a</td>\n",
       "      <td>tr</td>\n",
       "      <td>0.216216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0                   name_1  \\\n",
       "pair_id                                        \n",
       "1                 0           iko industries   \n",
       "2                 1       apcotex industries   \n",
       "3                 2   rishichem distributors   \n",
       "4                 3  powermax rubber factory   \n",
       "5                 4                 tress as   \n",
       "\n",
       "                                   name_2  is_duplicate  \\\n",
       "pair_id                                                   \n",
       "1               enormous industrial trade             0   \n",
       "2                  technocraft industries             0   \n",
       "3                                     dsa             0   \n",
       "4                                  co one             0   \n",
       "5        longyou industries park zhejiang             0   \n",
       "\n",
       "                     lemm_name_1                     lemm_name_2  \\\n",
       "pair_id                                                            \n",
       "1                   iko industry       enormous industrial trade   \n",
       "2               apcotex industry            technocraft industry   \n",
       "3          rishichem distributor                             dsa   \n",
       "4        powermax rubber factory                          co one   \n",
       "5                        tress a  longyou industry park zhejiang   \n",
       "\n",
       "                    stopw_name_1                    stopw_name_2  \\\n",
       "pair_id                                                            \n",
       "1                   iko industry       enormous industrial trade   \n",
       "2               apcotex industry            technocraft industry   \n",
       "3          rishichem distributor                             dsa   \n",
       "4        powermax rubber factory                          co one   \n",
       "5                          tress  longyou industry park zhejiang   \n",
       "\n",
       "                  clean_name_1  clean_name_2  ...  lemm_strcmp95  \\\n",
       "pair_id                                       ...                  \n",
       "1                          iko      enormous  ...       0.579852   \n",
       "2                          NaN   technocraft  ...       0.726726   \n",
       "3        rishichem distributor           NaN  ...       0.498413   \n",
       "4             powermax factory           NaN  ...       0.474396   \n",
       "5                        tress  longyou park  ...       0.528889   \n",
       "\n",
       "         lemm_needleman_wunsch  lemm_sorensen  lemm_tversky  lemm_overlap  \\\n",
       "pair_id                                                                     \n",
       "1                         -4.0       0.540541      0.370370      0.833333   \n",
       "2                          7.0       0.777778      0.636364      0.875000   \n",
       "3                        -16.0       0.166667      0.090909      0.666667   \n",
       "4                        -14.0       0.344828      0.208333      0.833333   \n",
       "5                        -19.0       0.324324      0.193548      0.857143   \n",
       "\n",
       "         lemm_monge_elkan  lemm_bag   lemm_lcsseq  lemm_lcsstr  \\\n",
       "pair_id                                                          \n",
       "1                0.069444        15     o industr      industr   \n",
       "2                0.054688         6  cot industry     industry   \n",
       "3                0.006803        19            ds            s   \n",
       "4                0.013233        18           o e            o   \n",
       "5                0.142857        24          tr a           tr   \n",
       "\n",
       "         lemm_ratcliff_obershelp  \n",
       "pair_id                           \n",
       "1                       0.486486  \n",
       "2                       0.611111  \n",
       "3                       0.083333  \n",
       "4                       0.137931  \n",
       "5                       0.216216  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 497819 entries, 1 to 497819\n",
      "Data columns (total 54 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   Unnamed: 0                 497819 non-null  int64  \n",
      " 1   name_1                     497819 non-null  object \n",
      " 2   name_2                     497819 non-null  object \n",
      " 3   is_duplicate               497819 non-null  int64  \n",
      " 4   lemm_name_1                497819 non-null  object \n",
      " 5   lemm_name_2                497819 non-null  object \n",
      " 6   stopw_name_1               497151 non-null  object \n",
      " 7   stopw_name_2               497134 non-null  object \n",
      " 8   clean_name_1               418795 non-null  object \n",
      " 9   clean_name_2               420898 non-null  object \n",
      " 10  levenstein                 497819 non-null  float64\n",
      " 11  norm_levenstein            497819 non-null  float64\n",
      " 12  partial_ratio              497819 non-null  float64\n",
      " 13  token_sort_ratio           497819 non-null  float64\n",
      " 14  token_set_ratio            497819 non-null  float64\n",
      " 15  WRatio                     497819 non-null  float64\n",
      " 16  partial_ratio_stopw        497819 non-null  float64\n",
      " 17  token_sort_ratio_stopw     497819 non-null  float64\n",
      " 18  token_set_ratio_stopw      497819 non-null  float64\n",
      " 19  WRatio_stopw               497819 non-null  float64\n",
      " 20  clean_jaccard              497819 non-null  float64\n",
      " 21  clean_cosine               497819 non-null  float64\n",
      " 22  clean_mra                  497819 non-null  int64  \n",
      " 23  clean_jaro_winkler         497819 non-null  float64\n",
      " 24  clean_hamming              497819 non-null  int64  \n",
      " 25  clean_mlipns               497819 non-null  int64  \n",
      " 26  clean_damerau_levenshtein  497819 non-null  int64  \n",
      " 27  clean_strcmp95             497819 non-null  float64\n",
      " 28  clean_needleman_wunsch     497819 non-null  float64\n",
      " 29  clean_sorensen             497819 non-null  float64\n",
      " 30  clean_tversky              497819 non-null  float64\n",
      " 31  clean_overlap              497819 non-null  float64\n",
      " 32  clean_monge_elkan          497819 non-null  float64\n",
      " 33  clean_bag                  497819 non-null  int64  \n",
      " 34  clean_lcsseq               309544 non-null  object \n",
      " 35  clean_lcsstr               309577 non-null  object \n",
      " 36  clean_ratcliff_obershelp   497819 non-null  float64\n",
      " 37  lemm_jaccard               497819 non-null  float64\n",
      " 38  lemm_cosine                497819 non-null  float64\n",
      " 39  lemm_mra                   497819 non-null  int64  \n",
      " 40  lemm_jaro_winkler          497819 non-null  float64\n",
      " 41  lemm_hamming               497819 non-null  int64  \n",
      " 42  lemm_mlipns                497819 non-null  int64  \n",
      " 43  lemm_damerau_levenshtein   497819 non-null  int64  \n",
      " 44  lemm_strcmp95              497819 non-null  float64\n",
      " 45  lemm_needleman_wunsch      497819 non-null  float64\n",
      " 46  lemm_sorensen              497819 non-null  float64\n",
      " 47  lemm_tversky               497819 non-null  float64\n",
      " 48  lemm_overlap               497819 non-null  float64\n",
      " 49  lemm_monge_elkan           497819 non-null  float64\n",
      " 50  lemm_bag                   497819 non-null  int64  \n",
      " 51  lemm_lcsseq                494778 non-null  object \n",
      " 52  lemm_lcsstr                494767 non-null  object \n",
      " 53  lemm_ratcliff_obershelp    497819 non-null  float64\n",
      "dtypes: float64(30), int64(12), object(12)\n",
      "memory usage: 208.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'name_1', 'name_2', 'is_duplicate', 'lemm_name_1',\n",
       "       'lemm_name_2', 'stopw_name_1', 'stopw_name_2', 'clean_name_1',\n",
       "       'clean_name_2', 'levenstein', 'norm_levenstein', 'partial_ratio',\n",
       "       'token_sort_ratio', 'token_set_ratio', 'WRatio', 'partial_ratio_stopw',\n",
       "       'token_sort_ratio_stopw', 'token_set_ratio_stopw', 'WRatio_stopw',\n",
       "       'clean_jaccard', 'clean_cosine', 'clean_mra', 'clean_jaro_winkler',\n",
       "       'clean_hamming', 'clean_mlipns', 'clean_damerau_levenshtein',\n",
       "       'clean_strcmp95', 'clean_needleman_wunsch', 'clean_sorensen',\n",
       "       'clean_tversky', 'clean_overlap', 'clean_monge_elkan', 'clean_bag',\n",
       "       'clean_lcsseq', 'clean_lcsstr', 'clean_ratcliff_obershelp',\n",
       "       'lemm_jaccard', 'lemm_cosine', 'lemm_mra', 'lemm_jaro_winkler',\n",
       "       'lemm_hamming', 'lemm_mlipns', 'lemm_damerau_levenshtein',\n",
       "       'lemm_strcmp95', 'lemm_needleman_wunsch', 'lemm_sorensen',\n",
       "       'lemm_tversky', 'lemm_overlap', 'lemm_monge_elkan', 'lemm_bag',\n",
       "       'lemm_lcsseq', 'lemm_lcsstr', 'lemm_ratcliff_obershelp'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ÐŸÐ°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð¾Ñ‚Ð±Ð¾Ñ€Ð°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "features_name = ['levenstein', 'norm_levenstein', 'partial_ratio',\n",
    "       'token_sort_ratio', 'token_set_ratio', 'WRatio', 'partial_ratio_stopw',\n",
    "       'token_sort_ratio_stopw', 'token_set_ratio_stopw', 'WRatio_stopw',\n",
    "       'clean_jaccard', 'clean_cosine', 'clean_mra', 'clean_jaro_winkler',\n",
    "       'clean_hamming', 'clean_mlipns', 'clean_damerau_levenshtein',\n",
    "       'clean_strcmp95', 'clean_needleman_wunsch', 'clean_sorensen',\n",
    "       'clean_tversky', 'clean_overlap', 'clean_monge_elkan', 'clean_bag', 'clean_ratcliff_obershelp',\n",
    "       'lemm_jaccard', 'lemm_cosine', 'lemm_mra', 'lemm_jaro_winkler',\n",
    "       'lemm_hamming', 'lemm_mlipns', 'lemm_damerau_levenshtein',\n",
    "       'lemm_strcmp95', 'lemm_needleman_wunsch', 'lemm_sorensen',\n",
    "       'lemm_tversky', 'lemm_overlap', 'lemm_monge_elkan', 'lemm_bag', 'lemm_ratcliff_obershelp']\n",
    "\n",
    "print(len(features_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X = train[features_name]\n",
    "X_norm = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "y = train['is_duplicate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11811024, 0.6       , 0.71      , ..., 0.03472222, 0.12      ,\n",
       "        0.48648649],\n",
       "       [0.07086614, 0.40909091, 0.72      , ..., 0.02734375, 0.048     ,\n",
       "        0.61111111],\n",
       "       [0.15748031, 0.90909091, 0.67      , ..., 0.00340136, 0.152     ,\n",
       "        0.08333333],\n",
       "       ...,\n",
       "       [0.11023622, 0.42424242, 0.7       , ..., 0.01331497, 0.056     ,\n",
       "        0.64615385],\n",
       "       [0.1023622 , 0.54166667, 0.59      , ..., 0.01736111, 0.056     ,\n",
       "        0.47826087],\n",
       "       [0.11811024, 0.55555556, 0.67      , ..., 0.02539062, 0.128     ,\n",
       "        0.41860465]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 40 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agladyshev/anaconda3/envs/unn-nlp/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 39 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agladyshev/anaconda3/envs/unn-nlp/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 38 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agladyshev/anaconda3/envs/unn-nlp/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 37 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agladyshev/anaconda3/envs/unn-nlp/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 36 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agladyshev/anaconda3/envs/unn-nlp/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 35 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agladyshev/anaconda3/envs/unn-nlp/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 34 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agladyshev/anaconda3/envs/unn-nlp/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 33 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agladyshev/anaconda3/envs/unn-nlp/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 32 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agladyshev/anaconda3/envs/unn-nlp/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 31 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agladyshev/anaconda3/envs/unn-nlp/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 30 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agladyshev/anaconda3/envs/unn-nlp/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 29 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agladyshev/anaconda3/envs/unn-nlp/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 28 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agladyshev/anaconda3/envs/unn-nlp/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 27 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agladyshev/anaconda3/envs/unn-nlp/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 26 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agladyshev/anaconda3/envs/unn-nlp/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 25 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agladyshev/anaconda3/envs/unn-nlp/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 24 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agladyshev/anaconda3/envs/unn-nlp/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 23 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agladyshev/anaconda3/envs/unn-nlp/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 22 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agladyshev/anaconda3/envs/unn-nlp/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 21 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agladyshev/anaconda3/envs/unn-nlp/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/home/agladyshev/anaconda3/envs/unn-nlp/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFE(estimator=LogisticRegression(), n_features_to_select=20, verbose=5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_selector = RFE(estimator=LogisticRegression(), n_features_to_select=num_features, step=1, verbose=5)\n",
    "rfe_selector.fit(X_norm, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 selected features\n"
     ]
    }
   ],
   "source": [
    "rfe_support = rfe_selector.get_support()\n",
    "rfe_feature = X.loc[:,rfe_support].columns.tolist()\n",
    "print(str(len(rfe_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['levenstein',\n",
       " 'norm_levenstein',\n",
       " 'partial_ratio',\n",
       " 'token_set_ratio',\n",
       " 'WRatio',\n",
       " 'token_sort_ratio_stopw',\n",
       " 'clean_jaccard',\n",
       " 'clean_jaro_winkler',\n",
       " 'clean_hamming',\n",
       " 'clean_damerau_levenshtein',\n",
       " 'clean_strcmp95',\n",
       " 'clean_sorensen',\n",
       " 'clean_tversky',\n",
       " 'clean_bag',\n",
       " 'lemm_cosine',\n",
       " 'lemm_jaro_winkler',\n",
       " 'lemm_hamming',\n",
       " 'lemm_damerau_levenshtein',\n",
       " 'lemm_strcmp95',\n",
       " 'lemm_bag']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso: SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LogisticRegression(penalty='l1', solver='liblinear'),\n",
       "                max_features=20)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "embeded_lr_selector = SelectFromModel(LogisticRegression(penalty=\"l1\", solver='liblinear'), max_features=num_features)\n",
    "embeded_lr_selector.fit(X_norm, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 selected features\n"
     ]
    }
   ],
   "source": [
    "embeded_lr_support = embeded_lr_selector.get_support()\n",
    "embeded_lr_feature = X.loc[:,embeded_lr_support].columns.tolist()\n",
    "print(str(len(embeded_lr_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['levenstein',\n",
       " 'norm_levenstein',\n",
       " 'partial_ratio',\n",
       " 'token_sort_ratio',\n",
       " 'token_set_ratio',\n",
       " 'WRatio',\n",
       " 'token_sort_ratio_stopw',\n",
       " 'clean_jaccard',\n",
       " 'clean_cosine',\n",
       " 'clean_jaro_winkler',\n",
       " 'clean_hamming',\n",
       " 'clean_strcmp95',\n",
       " 'clean_needleman_wunsch',\n",
       " 'clean_tversky',\n",
       " 'lemm_cosine',\n",
       " 'lemm_jaro_winkler',\n",
       " 'lemm_hamming',\n",
       " 'lemm_damerau_levenshtein',\n",
       " 'lemm_needleman_wunsch',\n",
       " 'lemm_bag']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_lr_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree-based: SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(), max_features=20)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "embeded_rf_selector = SelectFromModel(RandomForestClassifier(n_estimators=100), max_features=num_features)\n",
    "embeded_rf_selector.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 selected features\n"
     ]
    }
   ],
   "source": [
    "embeded_rf_support = embeded_rf_selector.get_support()\n",
    "embeded_rf_feature = X.loc[:,embeded_rf_support].columns.tolist()\n",
    "print(str(len(embeded_rf_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['partial_ratio',\n",
       " 'token_set_ratio',\n",
       " 'WRatio',\n",
       " 'partial_ratio_stopw',\n",
       " 'token_set_ratio_stopw',\n",
       " 'clean_jaro_winkler',\n",
       " 'clean_strcmp95',\n",
       " 'clean_needleman_wunsch',\n",
       " 'lemm_jaro_winkler',\n",
       " 'lemm_hamming',\n",
       " 'lemm_strcmp95',\n",
       " 'lemm_needleman_wunsch',\n",
       " 'lemm_overlap']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_rf_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-3.1.0-py2.py3-none-manylinux1_x86_64.whl (1.8 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.8 MB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/agladyshev/anaconda3/envs/unn-nlp/lib/python3.7/site-packages (from lightgbm) (1.5.2)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /home/agladyshev/anaconda3/envs/unn-nlp/lib/python3.7/site-packages (from lightgbm) (0.23.2)\n",
      "Requirement already satisfied: numpy in /home/agladyshev/anaconda3/envs/unn-nlp/lib/python3.7/site-packages (from lightgbm) (1.19.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/agladyshev/anaconda3/envs/unn-nlp/lib/python3.7/site-packages (from scikit-learn!=0.22.0->lightgbm) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/agladyshev/anaconda3/envs/unn-nlp/lib/python3.7/site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LGBMClassifier(colsample_bytree=0.2,\n",
       "                                         learning_rate=0.05,\n",
       "                                         min_child_weight=40,\n",
       "                                         min_split_gain=0.01, n_estimators=500,\n",
       "                                         num_leaves=32, reg_alpha=3,\n",
       "                                         reg_lambda=1),\n",
       "                max_features=20)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbc=LGBMClassifier(n_estimators=500, learning_rate=0.05, num_leaves=32, colsample_bytree=0.2,\n",
    "            reg_alpha=3, reg_lambda=1, min_split_gain=0.01, min_child_weight=40)\n",
    "\n",
    "embeded_lgb_selector = SelectFromModel(lgbc, max_features=num_features)\n",
    "embeded_lgb_selector.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 selected features\n"
     ]
    }
   ],
   "source": [
    "embeded_lgb_support = embeded_lgb_selector.get_support()\n",
    "embeded_lgb_feature = X.loc[:,embeded_lgb_support].columns.tolist()\n",
    "print(str(len(embeded_lgb_feature)), 'selected features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['norm_levenstein',\n",
       " 'token_sort_ratio',\n",
       " 'token_set_ratio',\n",
       " 'WRatio',\n",
       " 'token_sort_ratio_stopw',\n",
       " 'token_set_ratio_stopw',\n",
       " 'WRatio_stopw',\n",
       " 'clean_cosine',\n",
       " 'clean_jaro_winkler',\n",
       " 'clean_sorensen',\n",
       " 'clean_overlap',\n",
       " 'lemm_jaccard',\n",
       " 'lemm_hamming',\n",
       " 'lemm_needleman_wunsch',\n",
       " 'lemm_overlap',\n",
       " 'lemm_monge_elkan',\n",
       " 'lemm_ratcliff_obershelp']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeded_lgb_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ð¡Ñ€Ð°Ð²Ð½ÐµÐ½Ð¸Ðµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>RFE</th>\n",
       "      <th>Logistics</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>LightGBM</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>token_set_ratio</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lemm_hamming</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clean_jaro_winkler</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WRatio</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>token_sort_ratio_stopw</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>partial_ratio</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>norm_levenstein</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lemm_needleman_wunsch</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lemm_jaro_winkler</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>clean_strcmp95</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>token_sort_ratio</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>token_set_ratio_stopw</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>levenstein</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>lemm_strcmp95</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>lemm_overlap</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lemm_damerau_levenshtein</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>lemm_cosine</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>lemm_bag</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>clean_tversky</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>clean_sorensen</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Feature    RFE  Logistics  Random Forest  LightGBM  Total\n",
       "1            token_set_ratio   True       True           True      True      4\n",
       "2               lemm_hamming   True       True           True      True      4\n",
       "3         clean_jaro_winkler   True       True           True      True      4\n",
       "4                     WRatio   True       True           True      True      4\n",
       "5     token_sort_ratio_stopw   True       True          False      True      3\n",
       "6              partial_ratio   True       True           True     False      3\n",
       "7            norm_levenstein   True       True          False      True      3\n",
       "8      lemm_needleman_wunsch  False       True           True      True      3\n",
       "9          lemm_jaro_winkler   True       True           True     False      3\n",
       "10            clean_strcmp95   True       True           True     False      3\n",
       "11          token_sort_ratio  False       True          False      True      2\n",
       "12     token_set_ratio_stopw  False      False           True      True      2\n",
       "13                levenstein   True       True          False     False      2\n",
       "14             lemm_strcmp95   True      False           True     False      2\n",
       "15              lemm_overlap  False      False           True      True      2\n",
       "16  lemm_damerau_levenshtein   True       True          False     False      2\n",
       "17               lemm_cosine   True       True          False     False      2\n",
       "18                  lemm_bag   True       True          False     False      2\n",
       "19             clean_tversky   True       True          False     False      2\n",
       "20            clean_sorensen   True      False          False      True      2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# put all selection together\n",
    "feature_selection_df = pd.DataFrame({'Feature':features_name,\n",
    "                                     'RFE': rfe_support,\n",
    "                                     'Logistics': embeded_lr_support,\n",
    "                                     'Random Forest': embeded_rf_support,\n",
    "                                     'LightGBM': embeded_lgb_support})\n",
    "\n",
    "# count the selected times for each feature\n",
    "feature_selection_df['Total'] = np.sum(feature_selection_df, axis=1)\n",
    "\n",
    "feature_selection_df = feature_selection_df.sort_values(['Total', 'Feature'] , ascending=False)\n",
    "feature_selection_df.index = range(1, len(feature_selection_df) + 1)\n",
    "feature_selection_df.head(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['token_set_ratio',\n",
       " 'lemm_hamming',\n",
       " 'clean_jaro_winkler',\n",
       " 'WRatio',\n",
       " 'token_sort_ratio_stopw',\n",
       " 'partial_ratio',\n",
       " 'norm_levenstein',\n",
       " 'lemm_needleman_wunsch',\n",
       " 'lemm_jaro_winkler',\n",
       " 'clean_strcmp95',\n",
       " 'token_sort_ratio',\n",
       " 'token_set_ratio_stopw',\n",
       " 'levenstein',\n",
       " 'lemm_strcmp95',\n",
       " 'lemm_overlap',\n",
       " 'lemm_damerau_levenshtein',\n",
       " 'lemm_cosine',\n",
       " 'lemm_bag',\n",
       " 'clean_tversky',\n",
       " 'clean_sorensen',\n",
       " 'clean_needleman_wunsch',\n",
       " 'clean_jaccard',\n",
       " 'clean_hamming',\n",
       " 'clean_cosine',\n",
       " 'partial_ratio_stopw',\n",
       " 'lemm_ratcliff_obershelp',\n",
       " 'lemm_monge_elkan',\n",
       " 'lemm_jaccard',\n",
       " 'clean_overlap',\n",
       " 'clean_damerau_levenshtein',\n",
       " 'clean_bag',\n",
       " 'WRatio_stopw',\n",
       " 'lemm_tversky',\n",
       " 'lemm_sorensen',\n",
       " 'lemm_mra',\n",
       " 'lemm_mlipns',\n",
       " 'clean_ratcliff_obershelp',\n",
       " 'clean_mra',\n",
       " 'clean_monge_elkan',\n",
       " 'clean_mlipns']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_selection_df['Feature'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:unn-nlp] *",
   "language": "python",
   "name": "conda-env-unn-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
